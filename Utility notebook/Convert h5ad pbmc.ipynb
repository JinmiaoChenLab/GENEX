{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "451c10ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7f2a5837e0d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import random\n",
    "from numpy.random import default_rng\n",
    "from annoy import AnnoyIndex\n",
    "import torch.autograd as autograd\n",
    "from typing import List\n",
    "import anndata\n",
    "from functools import partial\n",
    "from copy import deepcopy\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn.metrics import (adjusted_rand_score, calinski_harabasz_score,\n",
    "                             normalized_mutual_info_score, silhouette_score)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import utils\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from random import sample\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import scanpy as sc\n",
    "import time\n",
    "import os\n",
    "from scipy import sparse\n",
    "\n",
    "from utils.explanation_utils import explanation_hook, get_explanation\n",
    "\n",
    "torch.cuda.set_device(2)\n",
    "\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "plt.ion()\n",
    "plt.show()\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "path= \"../\"\n",
    "\n",
    "# check available files\n",
    "# !ls ../real_data\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff055f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(\"data/pbmc.h5ad\")\n",
    "\n",
    "# storing the layers count\n",
    "adata.layers[\"counts\"] = adata.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6160c96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flavor: seurat_v3, cell_ranger & log = false\n",
    "def sub_data_preprocess(adata: sc.AnnData, n_top_genes: int = 5000, batch_key: str = None, flavor: str = 'seurat_v3', min_genes: int = 200, min_cells: int = 3) -> sc.AnnData:\n",
    "    sc.pp.filter_cells(adata, min_genes=min_genes)\n",
    "    sc.pp.filter_genes(adata, min_cells=min_cells)\n",
    "    if flavor == 'seurat_v3':\n",
    "# #         count data is expected when flavor=='seurat_v3'\n",
    "#         sc.pp.highly_variable_genes(\n",
    "#             adata, flavor=flavor, batch_key = batch_key)\n",
    "        sc.pp.highly_variable_genes(\n",
    "            adata, flavor=flavor, batch_key = batch_key, n_top_genes=n_top_genes)\n",
    "\n",
    "#     if flavor != 'seurat_v3':.\n",
    "#         # log-format data is expected when flavor!='seurat_v3'\n",
    "#         sc.pp.highly_variable_genes(\n",
    "#             adata, n_top_genes=n_top_genes, flavor=flavor)\n",
    "    sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    return adata\n",
    "\n",
    "\n",
    "def data_preprocess(adata: sc.AnnData, key: str = 'batch', n_top_genes: int = 10000, flavor: str = 'seurat_v3', min_genes: int = 200, min_cells: int = 3, n_batch: int = 2) -> sc.AnnData:\n",
    "    print('Establishing Adata for Next Step...')\n",
    "    hv_adata = sub_data_preprocess(adata, n_top_genes=n_top_genes, batch_key = key, flavor=flavor, min_genes=min_genes, min_cells=min_cells)\n",
    "    if len(adata.var.index) > n_top_genes:\n",
    "        hv_adata = hv_adata[:, hv_adata.var['highly_variable']]\n",
    "        \n",
    "#     hv_adata.X = np.expm1(hv_adata.X)\n",
    "    print('PreProcess Done.')\n",
    "    return hv_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07a256e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Establishing Adata for Next Step...\n",
      "PreProcess Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "View of AnnData object with n_obs × n_vars = 15476 × 10000\n",
       "    obs: 'Sample', 'n_counts', 'n_genes', 'batch', 'louvain', 'anno', 'Method', 'CellType'\n",
       "    var: 'gene_name', 'n_cells', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'highly_variable_nbatches'\n",
       "    uns: 'hvg', 'log1p'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_str = \"batch\"\n",
    "\n",
    "adata = data_preprocess(adata, batch_str)\n",
    "adata  # Output the basic information of the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74e30a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # apply the pre processing onto the anndata\n",
    "# # first create layer for the anndata\n",
    "# adata.layers[\"X_raw\"] = adata.X.copy()\n",
    "# adata.layers[\"X_scaled\"] = adata.X.copy()\n",
    "\n",
    "# # split per batch into new objects.\n",
    "# batches = list(set(adata.obs['batch']))\n",
    "# # alldata_2 = {}\n",
    "\n",
    "# # apply scaling to each batch in the pre process raw data\n",
    "# for batch in batches:\n",
    "# #     alldata[batch] = adata_int[adata_int.obs['Batch'] == batch,]\n",
    "\n",
    "#     batch_index = adata.obs['batch'] == batch\n",
    "#     temp_X = adata[batch_index].X\n",
    "    \n",
    "#     # log normalise data the same seurat\n",
    "# #     sc.pp.normalize_per_cell(temp_adata, counts_per_cell_after = 1e4)\n",
    "# #     sc.pp.log1p(temp_adata)\n",
    "# #     temp_adata.layers[\"X_norm\"] = temp_adata.X\n",
    "    \n",
    "#     # scaling of the data for PCA and UMAP embedding\n",
    "#     temp_X_scaled = sc.pp.scale(temp_X, copy = True)\n",
    "#     adata[batch_index].layers[\"X_scaled\"] = temp_X_scaled\n",
    "\n",
    "# # use this pancreatic data since it has been normalised already based on the author\n",
    "# # adata.X = adata.layers[\"X_raw\"].copy() # change to norm for count dataset\n",
    "\n",
    "# # this is use for UMAP generation only for the raw dataset\n",
    "# # adata.X = adata.layers[\"X_scaled\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52bd9a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.to_csv(\"metadata_cell_pbmc_full.csv\", index = False)\n",
    "adata.var.to_csv(\"metadata_gene_pbmc_full.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a61f1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(adata.X.transpose()).to_csv(\"count_matrix_pbmc_full.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4c3455",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "clear"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
